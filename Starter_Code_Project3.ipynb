{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction and Storage\n",
    "\n",
    "## Overview\n",
    "\n",
    "This code contains the data extraction and storage functionalities for our project. The data is sourced directly from the CDC's website: [CDC Flu Data](https://www.cdc.gov/flu/weekly/usmap.htm). \n",
    "\n",
    "## Details of Work Performed\n",
    "\n",
    "### Data Extraction and Cleaning\n",
    "- **Source**: Data was sourced from the CDC website.\n",
    "- **Cleaning**: The data was cleaned and formatted to ensure consistency and accuracy. This involved handling missing values, standardizing date formats, and ensuring the data is in a usable state.\n",
    "\n",
    "### Database Schema Design\n",
    "- **Database**: SQLite was chosen for its simplicity and ease of use for this project.\n",
    "- **Schema**: The `StateData` model includes fields for `state`, `activity_level`, `activity_level_label`, `weekend`, `week`, and `season`.\n",
    "\n",
    "### Flask Application Setup\n",
    "- **API Endpoints**: Implemented API endpoints to serve the data. The main endpoint `/api/flu-data` returns the overall flu data in JSON format.\n",
    "- **App Configuration**: Configured the Flask app to connect to the SQLite database and defined the necessary models.\n",
    "\n",
    "### Scheduling and Updates\n",
    "- **Periodic Updates**: Implemented a scheduling mechanism using a tool like `APScheduler` to automate daily updates to the data.\n",
    "- **Script**: The `update_data.py` script handles the fetching, cleaning, and storing of new data on a daily basis.\n",
    "\n",
    "## Contribution\n",
    "\n",
    "This starter code was completed by Joy Ragland. \n",
    "\n",
    "The associated tasks included:\n",
    "\n",
    "- Creating the initial codebase for data extraction and storage.\n",
    "- Setting up the Flask application and defining the database schema.\n",
    "- Implementing the scheduling mechanism for periodic data updates.\n",
    "- Documenting the data extraction and storage process.\n",
    "\n",
    "This work ensures that our application serves up-to-date and accurate flu data, providing a solid foundation for further development and integration.\n",
    "\n",
    "## Missing Code can be found in the Data Extraction & Storage Branch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial State Data DataFrame:\n",
      "  STATENAME                         URL                 WEBSITE  \\\n",
      "0   Alabama  http://adph.org/influenza/  Influenza Surveillance   \n",
      "1   Alabama  http://adph.org/influenza/  Influenza Surveillance   \n",
      "2   Alabama  http://adph.org/influenza/  Influenza Surveillance   \n",
      "3   Alabama  http://adph.org/influenza/  Influenza Surveillance   \n",
      "4   Alabama  http://adph.org/influenza/  Influenza Surveillance   \n",
      "\n",
      "  ACTIVITY LEVEL ACTIVITY LEVEL LABEL      WEEKEND  WEEK   SEASON  \n",
      "0        Level 1              Minimal  Oct-11-2008    41  2008-09  \n",
      "1        Level 1              Minimal  Oct-18-2008    42  2008-09  \n",
      "2        Level 1              Minimal  Oct-25-2008    43  2008-09  \n",
      "3        Level 3              Minimal  Nov-01-2008    44  2008-09  \n",
      "4        Level 1              Minimal  Nov-08-2008    45  2008-09  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from the State Data CSV file into a DataFrame\n",
    "state_data_df = pd.read_csv('StateDatabySeason63_49,48,62.csv')\n",
    "\n",
    "# Display the initial DataFrame\n",
    "print(\"Initial State Data DataFrame:\")\n",
    "print(state_data_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned State Data DataFrame:\n",
      "    States ACTIVITY LEVEL ACTIVITY LEVEL LABEL    WEEKEND  WEEK   SEASON  YEAR\n",
      "0  Alabama        Level 1              Minimal 2008-10-11    41  2008-09  2008\n",
      "1  Alabama        Level 1              Minimal 2008-10-18    42  2008-09  2008\n",
      "2  Alabama        Level 1              Minimal 2008-10-25    43  2008-09  2008\n",
      "3  Alabama        Level 3              Minimal 2008-11-01    44  2008-09  2008\n",
      "4  Alabama        Level 1              Minimal 2008-11-08    45  2008-09  2008\n"
     ]
    }
   ],
   "source": [
    "# Columns to drop and the column to rename\n",
    "state_data_drop_columns = ['URL', 'WEBSITE']  \n",
    "state_data_rename_columns = {'STATENAME': 'States'}  \n",
    "\n",
    "# Drop unnecessary columns\n",
    "state_data_df = state_data_df.drop(columns=state_data_drop_columns, errors='ignore')\n",
    "\n",
    "# Rename the column Statename\n",
    "state_data_df = state_data_df.rename(columns=state_data_rename_columns)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(\"Cleaned State Data DataFrame:\")\n",
    "print(state_data_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to 'Cleaned_StateDatabySeason63_49,48,62.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned data to a new CSV file\n",
    "state_data_df.to_csv('Cleaned_StateDatabySeason63_49,48,62.csv', index=False)\n",
    "\n",
    "print(\"Cleaned data saved to 'Cleaned_StateDatabySeason63_49,48,62.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['States', 'ACTIVITY LEVEL', 'ACTIVITY LEVEL LABEL', 'WEEKEND', 'WEEK',\n",
      "       'SEASON', 'YEAR'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/49/dwr6y0hj2ks1d2zvzxbjk6080000gn/T/ipykernel_44780/578025478.py:25: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully added to the SQLite database.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# Load the cleaned data from the new CSV file into a DataFrame\n",
    "state_data_df = pd.read_csv('Cleaned_StateDatabySeason63_49,48,62.csv')\n",
    "\n",
    "# Display the column names\n",
    "print(state_data_df.columns)\n",
    "\n",
    "# Rename columns if necessary (for demonstration, you may need to adapt this)\n",
    "state_data_df = state_data_df.rename(columns={\n",
    "    'States': 'state', \n",
    "    'ACTIVITY LEVEL': 'activity_level', \n",
    "    'ACTIVITY LEVEL LABEL': 'activity_level_label', \n",
    "    'WEEKEND': 'weekend', \n",
    "    'WEEK': 'week', \n",
    "    'SEASON': 'season'\n",
    "})\n",
    "\n",
    "# Define the SQLite database\n",
    "engine = create_engine('sqlite:///state_data.db')\n",
    "Base = declarative_base()\n",
    "\n",
    "# Define the StateData class to map to the SQLite table\n",
    "class StateData(Base):\n",
    "    __tablename__ = 'state_data'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    state = Column(String)\n",
    "    activity_level = Column(String)\n",
    "    activity_level_label = Column(String)\n",
    "    weekend = Column(String)\n",
    "    week = Column(Integer)\n",
    "    season = Column(String)\n",
    "\n",
    "# Create the table in the database\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "# Create a session to interact with the database\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Insert the cleaned data into the database\n",
    "for index, row in state_data_df.iterrows():\n",
    "    state_data = StateData(\n",
    "        state=row['state'],\n",
    "        activity_level=row['activity_level'],\n",
    "        activity_level_label=row['activity_level_label'],\n",
    "        weekend=row['weekend'],\n",
    "        week=row['week'],\n",
    "        season=row['season']\n",
    "    )\n",
    "    session.add(state_data)\n",
    "\n",
    "# Commit the session to save the data\n",
    "session.commit()\n",
    "\n",
    "# Close the session\n",
    "session.close()\n",
    "\n",
    "print(\"Data successfully added to the SQLite database.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
